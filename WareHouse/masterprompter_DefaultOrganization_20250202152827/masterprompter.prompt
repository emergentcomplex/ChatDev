I want you to use whisper voice to text 'tiny' model to record my speech and upload the translation to openai api request. This should be auto-stopped once a threshold minimim db average exceeds a limit at a duration. We should set this to -35db for 2.5s dutation. Trim out this excess before sending it off to openai api. Then I want you to stream out the response in the console. You should use kokoru to convert the dialogue output back to the user as a generated voice